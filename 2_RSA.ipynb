{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for the RSA analysis of Morbi EEG project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import mne\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import rankdata,pearsonr\n",
    "from neurora.stuff import permutation_corr\n",
    "from mne.viz import plot_topomap\n",
    "from mne.stats import fdr_correction\n",
    "from scipy.stats import ttest_1samp, ttest_ind, ttest_rel, f_oneway\n",
    "from mne.stats import fdr_correction, f_mway_rm, permutation_cluster_test\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3') \n",
    "from Function import get_tril_vec, spearmanr, permutation_cor\n",
    "\n",
    "\n",
    "# define data repository\n",
    "behav_path = 'E:/Bilingual_Morphology_Project/Data/Behav/'\n",
    "eeg_path = 'E:/Bilingual_Morphology_Project/Data/EEG_prep'\n",
    "vec_path = 'E:/Bilingual_Morphology_Project/Data/word_vec/'\n",
    "results_path = 'E:/Bilingual_Morphology_Project/Results/'\n",
    "plot_path = 'E:/Bilingual_Morphology_Project/Results/Plot'\n",
    "\n",
    "sub_list = list(range(5,35))\n",
    "mark_list = list(range(2,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Representational similarity matrix of Word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the word vectors as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chinese words vectors (200 dimesnions)\n",
    "vec_cpp1 = pd.read_pickle(os.path.join(vec_path,'CH/vec_cpp1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_cpp2 = pd.read_pickle(os.path.join(vec_path,'CH/vec_cpp2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_cpn1 = pd.read_pickle(os.path.join(vec_path,'CH/vec_cpn1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_cpn2 = pd.read_pickle(os.path.join(vec_path,'CH/vec_cpn2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ccp1 = pd.read_pickle(os.path.join(vec_path,'CH/vec_ccp1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ccp2 = pd.read_pickle(os.path.join(vec_path,'CH/vec_ccp2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ccn1 = pd.read_pickle(os.path.join(vec_path,'CH/vec_ccn1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ccn2 = pd.read_pickle(os.path.join(vec_path,'CH/vec_ccn2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "\n",
    "# load the english words vectors (300 dimensions)\n",
    "vec_epp1 = pd.read_pickle(os.path.join(vec_path,'EN/vec_epp1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_epp2 = pd.read_pickle(os.path.join(vec_path,'EN/vec_epp2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_epn1 = pd.read_pickle(os.path.join(vec_path,'EN/vec_epn1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_epn2 = pd.read_pickle(os.path.join(vec_path,'EN/vec_epn2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ecp1 = pd.read_pickle(os.path.join(vec_path,'EN/vec_ecp1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ecp2 = pd.read_pickle(os.path.join(vec_path,'EN/vec_ecp2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ecn1 = pd.read_pickle(os.path.join(vec_path,'EN/vec_ecn1.pkl')).iloc[:,1:].to_numpy().astype(np.float64)\n",
    "vec_ecn2 = pd.read_pickle(os.path.join(vec_path,'EN/vec_ecn2.pkl')).iloc[:,1:].to_numpy().astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance of word vectors between primer and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the pearson r as distance\n",
    "vec_r_cpp = []\n",
    "for i in range(vec_cpp1.shape[0]):\n",
    "    vec1,vec2 = vec_cpp1[i,:],vec_cpp2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_cpp.append(r)\n",
    "vec_r_cpp = np.array(vec_r_cpp)\n",
    "\n",
    "vec_r_cpn = []\n",
    "for i in range(vec_cpn1.shape[0]):\n",
    "    vec1,vec2 = vec_cpn1[i,:],vec_cpn2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_cpn.append(r)\n",
    "vec_r_cpn = np.array(vec_r_cpn)\n",
    "vec_r_cpn = np.append(vec_r_cpn, [[vec_r_cpn.mean(),vec_r_cpn.mean()]])\n",
    "\n",
    "vec_r_ccp = []\n",
    "for i in range(vec_ccp1.shape[0]):\n",
    "    vec1,vec2 = vec_ccp1[i,:],vec_ccp2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_ccp.append(r)\n",
    "vec_r_ccp = np.array(vec_r_ccp)\n",
    "\n",
    "vec_r_ccn = []\n",
    "for i in range(vec_ccn1.shape[0]):\n",
    "    vec1,vec2 = vec_ccn1[i,:],vec_ccn2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_ccn.append(r)\n",
    "vec_r_ccn = np.array(vec_r_ccn)\n",
    "\n",
    "vec_r_epp = []\n",
    "for i in range(vec_epp1.shape[0]):\n",
    "    vec1,vec2 = vec_epp1[i,:],vec_epp2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_epp.append(r)\n",
    "vec_r_epp = np.array(vec_r_epp)\n",
    "\n",
    "vec_r_epn = []\n",
    "for i in range(vec_epn1.shape[0]):\n",
    "    vec1,vec2 = vec_epn1[i,:],vec_epn2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_epn.append(r)\n",
    "vec_r_epn = np.array(vec_r_epn)\n",
    "vec_r_epn = np.append(vec_r_epn, [[vec_r_epn.mean()]])\n",
    "\n",
    "vec_r_ecp = []\n",
    "for i in range(vec_ecp1.shape[0]):\n",
    "    vec1,vec2 = vec_ecp1[i,:],vec_ecp2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_ecp.append(r)\n",
    "vec_r_ecp = np.array(vec_r_ecp)\n",
    "\n",
    "vec_r_ecn = []\n",
    "for i in range(vec_ecn1.shape[0]):\n",
    "    vec1,vec2 = vec_ecn1[i,:],vec_ecn2[i,:]\n",
    "    r = 1 - np.linalg.norm(vec2-vec1)\n",
    "    vec_r_ecn.append(r)\n",
    "vec_r_ecn = np.array(vec_r_ecn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_con = 8\n",
    "# vec = np.array([vec_r_cpp.mean(),vec_r_cpn.mean(),vec_r_ccp.mean(),vec_r_ccn.mean(),\\\n",
    "#         vec_r_epp.mean(),vec_r_epn.mean(),vec_r_ecp.mean(),vec_r_ecn.mean()])\n",
    "# vec_rank = rankdata(vec) # explicity convert the raw scores to ranks\n",
    "# nn_vec = np.zeros((n_con, n_con))\n",
    "\n",
    "# for i in range(n_con):\n",
    "#     for j in range(n_con):\n",
    "#         if i < j:\n",
    "#             dist_ij = 1-(abs(vec_rank[i]-vec_rank[j])/n_con) \n",
    "#             nn_vec[i,j] = dist_ij\n",
    "#             nn_vec[j,i] = dist_ij\n",
    "             \n",
    "# np.fill_diagonal(nn_vec, 1)\n",
    "\n",
    "# # mask =np.zeros_like(nn_vec)\n",
    "# # mask[np.triu_indices_from(mask)] = True\n",
    "# plt.figure(figsize=(20,10))\n",
    "# sns.heatmap(nn_vec, square=True, cmap='RdBu_r', linewidths=0.1,  xticklabels=False, yticklabels=False, cbar_kws={'label': 'similarity', \"shrink\": 0.8})\n",
    "# plt.title('', fontsize=25, fontweight='bold')\n",
    "\n",
    "# wordvec_rsm_nn = get_tril_vec(nn_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_con = 8\n",
    "vec = np.array([vec_r_cpp.mean(),vec_r_cpn.mean(),vec_r_ccp.mean(),vec_r_ccn.mean(),\\\n",
    "        vec_r_epp.mean(),vec_r_epn.mean(),vec_r_ecp.mean(),vec_r_ecn.mean()])\n",
    "vec_rank = rankdata(vec) # explicity convert the raw scores to ranks\n",
    "annk_vec = np.zeros((n_con, n_con))\n",
    "\n",
    "for i in range(n_con):\n",
    "    for j in range(n_con):\n",
    "        if i < j:\n",
    "            sim_ij = np.mean([vec_rank[i], vec_rank[j]])/n_con\n",
    "            annk_vec[i,j] = sim_ij\n",
    "            annk_vec[j,i] = sim_ij\n",
    "        elif i==j:\n",
    "            annk_vec[i,j] = 1\n",
    "             \n",
    "np.fill_diagonal(annk_vec, 1)\n",
    "wordvec_rsm_annk = get_tril_vec(annk_vec)\n",
    "\n",
    "annk_vec = pd.DataFrame(annk_vec)\n",
    "annk_vec.columns = ['Chinese priming people-rlated','Chinese priming people unrelated','Chinese control people related','Chinese control people unrelated','English priming people-rlated','English priming people unrlated','English control people-rlated','English control people unrlated']\n",
    "annk_vec.index = ['Chinese priming people-rlated','Chinese priming people unrelated','Chinese control people related','Chinese control people unrelated','English priming people-rlated','English priming people unrlated','English control people-rlated','English control people unrlated']\n",
    "mask =np.zeros_like(annk_vec)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(annk_vec, square=True, cmap='RdBu_r', linewidths=0.1,xticklabels=False, yticklabels=True, cbar_kws={'label': 'similarity', \"shrink\": 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordvec = np.stack([vec_r_cpp, vec_r_cpn, vec_r_ccp, vec_r_ccn, vec_r_epp, vec_r_epn, vec_r_ecp, vec_r_ecn], axis=1)\n",
    "# wordvec_rsm = 1-pdist(wordvec.T, metric='correlation')\n",
    "# wordvec_rsm_square = squareform(wordvec_rsm)\n",
    "\n",
    "# # mask =np.zeros_like(wordvec_rsm_square)\n",
    "# # mask[np.triu_indices_from(mask)] = True\n",
    "# plt.figure(figsize=(20,10))\n",
    "# sns.heatmap(wordvec_rsm_square, square=True, cmap='RdBu_r', linewidths=0.1,  xticklabels=False, yticklabels=False, cbar_kws={'label': 'similarity', \"shrink\": 0.8})\n",
    "# plt.title('RSM of word vectors distance (all pairs)', fontsize=25, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Representational similarity matrix of ERP scalp distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = mne.read_epochs_eeglab('E:/Bilingual_Morphology_Project/Data/EEG_prep/S31_09.set')\n",
    "montage_file = 'E:/Bilingual_Morphology_Project/Scripts/morbi.loc'\n",
    "montage = mne.channels.read_custom_montage(montage_file)\n",
    "demo.set_montage(montage)\n",
    "\n",
    "eeg_meta = {}\n",
    "for sub in sub_list:\n",
    "    conditions = {}\n",
    "    for mark in mark_list:\n",
    "        tp = mne.read_epochs_eeglab(os.path.join(eeg_path, 'S' + str(sub) + '_0'+ str(mark) + '.set'))\n",
    "        tp.set_montage(montage)\n",
    "        conditions[mark] = tp\n",
    "    eeg_meta[sub] = conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel indexing\n",
    "# Obtain the channel names as a list\n",
    "ch_names = eeg_meta[5][2].ch_names\n",
    "print(ch_names)\n",
    "# Crate a index list for channels\n",
    "ch_idx = list(range(31))\n",
    "# Combine the channels and index and convert to a dict\n",
    "ch_num = dict(zip(ch_names, ch_idx))\n",
    "print(ch_num['PO9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_meta, ccp_meta, epp_meta, ecp_meta, cpn_meta, ccn_meta, epn_meta, ecn_meta = {}, {}, {}, {}, {}, {}, {}, {}\n",
    "for sub in sub_list:\n",
    "    epoch = eeg_meta[sub]\n",
    "    # Convert data to numpy array\n",
    "    cpp = epoch[2].get_data()*10**6  # Chinese priming condition\n",
    "    cpn = epoch[3].get_data()*10**6\n",
    "    ccp = epoch[4].get_data()*10**6  # Chinese control condition\n",
    "    ccn = epoch[5].get_data()*10**6 \n",
    "    epp = epoch[6].get_data()*10**6  # English priming condition  \n",
    "    epn = epoch[7].get_data()*10**6\n",
    "    ecp = epoch[9].get_data()*10**6  # English control condition\n",
    "    ecn = epoch[8].get_data()*10**6\n",
    "    \n",
    "    cpp_meta[sub], ccp_meta[sub], epp_meta[sub], ecp_meta[sub], \\\n",
    "                    cpn_meta[sub], ccn_meta[sub], epn_meta[sub], ecn_meta[sub] = cpp, cpn, ccp, ccn, epp, epn, ecp, ecn\n",
    "\n",
    "\n",
    "# ERP data structure: [n_channels, n_sub, n_times]\n",
    "cpp_erp, cpn_erp, ccp_erp, ccn_erp, epp_erp, epn_erp, ecp_erp, ecn_erp \\\n",
    "            = np.zeros([31,30,500]), np.zeros([31,30,500]), np.zeros([31,30,500]), np.zeros([31,30,500]), \\\n",
    "            np.zeros([31,30,500]), np.zeros([31,30,500]), np.zeros([31,30,500]), np.zeros([31,30,500])\n",
    "# Loop across all channels and subjects\n",
    "for ch in ch_idx:\n",
    "    for sub in sub_list:\n",
    "        cpp_erp[ch,sub-5,:] = np.average(cpp_meta[sub][:,ch,:], axis=0)\n",
    "        cpn_erp[ch,sub-5,:] = np.average(cpn_meta[sub][:,ch,:], axis=0)\n",
    "        ccp_erp[ch,sub-5,:] = np.average(ccp_meta[sub][:,ch,:], axis=0)\n",
    "        ccn_erp[ch,sub-5,:] = np.average(ccn_meta[sub][:,ch,:], axis=0)\n",
    "        epp_erp[ch,sub-5,:] = np.average(epp_meta[sub][:,ch,:], axis=0)\n",
    "        epn_erp[ch,sub-5,:] = np.average(epn_meta[sub][:,ch,:], axis=0)\n",
    "        ecp_erp[ch,sub-5,:] = np.average(ecp_meta[sub][:,ch,:], axis=0)\n",
    "        ecn_erp[ch,sub-5,:] = np.average(ecn_meta[sub][:,ch,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_rsm = np.zeros((28,30,500)) # n-pair of similarity * n-timepoints * n-subjects\n",
    "for sub in sub_list:\n",
    "    for i in range(500):\n",
    "        cpp, cpn, ccp, ccn, epp, epn, ecp, ecn = cpp_erp[:,sub-5,i], cpn_erp[:,sub-5,i], ccp_erp[:,sub-5,i], ccn_erp[:,sub-5,i], \\\n",
    "                epp_erp[:,sub-5,i], epn_erp[:,sub-5,i], ecp_erp[:,sub-5,i], ecn_erp[:,sub-5,i]\n",
    "        rep = np.stack([cpp,cpn,ccp,ccn,epp,epn,ecp,ecn],axis=1)\n",
    "        simi = 1-pdist(rep.T, metric='correlation')\n",
    "        neural_rsm[:,sub-5,i] = simi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_rsm = squareform(np.average(neural_rsm.mean(axis=1),axis=1))\n",
    "np.fill_diagonal(eeg_rsm, 1)\n",
    "\n",
    "eeg_rsm = pd.DataFrame(eeg_rsm)\n",
    "eeg_rsm.columns = ['Chinese priming people-rlated','Chinese priming people unrelated','Chinese control people related','Chinese control people unrelated','English priming people-rlated','English priming people unrlated','English control people-rlated','English control people unrlated']\n",
    "eeg_rsm.index = ['Chinese priming people-rlated','Chinese priming people unrelated','Chinese control people related','Chinese control people unrelated','English priming people-rlated','English priming people unrlated','English control people-rlated','English control people unrlated']\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(eeg_rsm, square=True, cmap='RdBu_r', vmax=0.65,vmin=0.5,linewidths=0.1,xticklabels=False, yticklabels=True, cbar_kws={'label': 'similarity', \"shrink\": 0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectio 3: Representational similarity analysis of wordvec & ERP\n",
    "\n",
    "Annk method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define RSA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralvec_rsa(i,sub,neural_rsm,wordvec_rsm):\n",
    "    r = spearmanr(neural_rsm[:,sub,i],wordvec_rsm)\n",
    "    p = permutation_corr(neural_rsm[:,sub,i],wordvec_rsm, method='spearman', iter=10000)\n",
    "    \n",
    "    return [r,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralvec_rsa_mean(i,neural_rsm,wordvec_rsm):\n",
    "    r = spearmanr(neural_rsm[:,i],wordvec_rsm)\n",
    "    p = permutation_corr(neural_rsm[:,i],wordvec_rsm, method='spearman', iter=10000)\n",
    "    return [r,p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grand average across all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sub = Parallel(n_jobs=8)(delayed(neuralvec_rsa_mean)(i,neural_rsm.mean(axis=1),wordvec_rsm_annk) for i in range(500))\n",
    "\n",
    "mean_r,mean_p = [],[]\n",
    "for i in range(500):\n",
    "    mean_r.append(mean_sub[i][0])\n",
    "    mean_p.append(mean_sub[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the RSA r value\n",
    "times = np.arange(-200, 800, 2)\n",
    "plt.figure(figsize=(20,12))\n",
    "ax = plt.axes()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "ax.spines['left'].set_linewidth(3)\n",
    "plt.tick_params(direction='in',length=10,width=3,labelsize=20)\n",
    "plt.xlim(-200,800)\n",
    "plt.ylim(-1,1)\n",
    "plt.grid()\n",
    "\n",
    "# Plot the r value\n",
    "plt.plot(times, np.array(mean_r), alpha=0.9,lw=3)\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\",lw=2)\n",
    "plt.axhline(y=0, color=\"black\",lw=2)\n",
    "plt.xlabel('Time (ms)',fontdict={'family':'Arial', 'weight':'bold','size':25})\n",
    "plt.ylabel('Spearman rho', fontdict={'family':'Arial', 'weight':'bold','size':25})\n",
    "#plt.title(str(title),fontdict={'family':'Arial', 'weight':'bold','size':20})\n",
    "plt.savefig(os.path.join(plot_path,'rsa.png'),bbox_inches='tight',dpi=600,pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the RSA r value\n",
    "times = np.arange(-200, 800, 2)\n",
    "plt.figure(figsize=(20,12))\n",
    "ax = plt.axes()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_linewidth(3)\n",
    "ax.spines['left'].set_linewidth(3)\n",
    "plt.tick_params(direction='in',length=10,width=3,labelsize=20)\n",
    "plt.xlim(-200,800)\n",
    "plt.ylim(0,0.05)\n",
    "plt.grid()\n",
    "\n",
    "# Plot the r value\n",
    "plt.plot(times, np.array(mean_p), alpha=0.9,lw=3)\n",
    "plt.axvline(x=0, color=\"black\", linestyle=\"--\",lw=2)\n",
    "plt.axhline(y=0, color=\"black\",lw=2)\n",
    "plt.xlabel('Time (ms)',fontdict={'family':'Arial', 'weight':'bold','size':25})\n",
    "plt.ylabel('Spearman rho', fontdict={'family':'Arial', 'weight':'bold','size':25})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct RSA on each subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsa_r_meta, rsa_p_meta = np.zeros((500,30)), np.zeros((500,30))\n",
    "\n",
    "for sub in tqdm(sub_list):\n",
    "    sing_sub = Parallel(n_jobs=8)(delayed(neuralvec_rsa)(i,sub-5,neural_rsm,wordvec_rsm_annk) for i in range(500))\n",
    "\n",
    "    rsa_r,rsa_p = [],[]\n",
    "    for i in range(500):\n",
    "        rsa_r.append(sing_sub[i][0])\n",
    "        rsa_p.append(sing_sub[i][1])\n",
    "    \n",
    "    rsa_r_meta[:,sub-5], rsa_p_meta[:,sub-5] = np.array(rsa_r), np.array(rsa_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(results_path,'rsa_r_allsub.npy'),rsa_r_meta)\n",
    "np.save(os.path.join(results_path,'rsa_p_allsub.npy'),rsa_p_meta)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0637cefd005ce32f53abe336a7c6e0206dbf0dc1ed7f0aa326c4767b89ff415c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('EEG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
